{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy Question Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmF4jfkhIS7rjdmGCtbZe/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathula31/FYP/blob/main/Question_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rtPYlepdkV9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYsZ4-igd6Wy"
      },
      "source": [
        "**sentence transformer install**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYuh4MP2eCcb",
        "outputId": "80f830fe-1906-4434-c0b5-5dc610df1159"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/5a/6e41e8383913dd2ba923cdcd02be2e03911595f4d2f9de559ecbed80d2d3/sentence-transformers-0.3.9.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.8MB/s \n",
            "\u001b[?25hCollecting transformers<3.6.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 12.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 30.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 38.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence-transformers) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.6.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<3.6.0,>=3.1.0->sentence-transformers) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.6.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.9-cp36-none-any.whl size=101036 sha256=0c0ce9bb9d8dfb6b8b9ae67b68d399fc29c47ca0b49bede0d37d00bcc0c24cb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/89/43/f2f5bc00b03ef9724b0f6254a97eaf159a4c4ddc024b33e07a\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4055954b77da27a5a469b31ebb75b84cf37af5b68692a5989e83466714a9853a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.9 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcsCuK6teSvJ"
      },
      "source": [
        "**import sentence_transformers and sklearn kmeans**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4By3ZMKteYS3"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxJdN-AIe_8w"
      },
      "source": [
        "Create sentence transformer object using pretrained model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkkwvmYHfTA_"
      },
      "source": [
        "embedder = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OreJobXRfi5q"
      },
      "source": [
        "make questions into list\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMx_yMtafkwL"
      },
      "source": [
        "corpus = ['What is known about transmission, incubation, and environmental stability?',\n",
        "          'What do we know about COVID-19 risk factors?',\n",
        "          'What do we know about vaccines and therapeutics?',\n",
        "          'What do we know about virus genetics, origin, and evolution?',\n",
        "          'What has been published about medical care?',\n",
        "          'What do we know about non-pharmaceutical interventions?',\n",
        "          'What has been published about ethical and social science considerations?',\n",
        "          'What do we know about diagnostics and surveillance?',\n",
        "          'What has been published about information sharing and inter-sectoral collaboration?',\n",
        "          'Create summary tables that address relevant factors related to COVID-19?',\n",
        "          'Create summary tables that address therapeutics, interventions, and clinical studies?',\n",
        "          'Create summary tables that address risk factors related to COVID-19?',\n",
        "          'Create summary tables that address diagnostics for COVID-19?',\n",
        "          'Create summary tables that address material studies related to COVID-19?',\n",
        "          'Create summary tables that address population studies related to COVID-19?',\n",
        "          'Create summary tables that address models and open questions related to COVID-19?',\n",
        "          'Create summary tables that address patient descriptions related to COVID-19'\n",
        "\n",
        "          ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbdwwdXUf7uc"
      },
      "source": [
        "Generate embedding for each of the questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD_yMXZngDe-"
      },
      "source": [
        "corpus_embeddings = embedder.encode(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpsi2FMkgMI4"
      },
      "source": [
        "cluster the  questions using BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v6lMCTMgXHN"
      },
      "source": [
        "num_clusters = 6\n",
        "# Define kmeans model\n",
        "clustering_model = KMeans(n_clusters=num_clusters)\n",
        "\n",
        "# Fit the embedding with kmeans clustering.\n",
        "clustering_model.fit(corpus_embeddings)\n",
        "\n",
        "# Get the cluster id assigned to each news headline.\n",
        "cluster_assignment = clustering_model.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFQMTZaogzmk"
      },
      "source": [
        "see the cluster id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLD5IfDlg435",
        "outputId": "9a1dcceb-ce89-4ff9-c47a-1553a52927c6"
      },
      "source": [
        "print(cluster_assignment)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 5 2 2 2 4 1 2 3 5 0 5 0 5 0 5 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtdw3OzbhGEv"
      },
      "source": [
        "see the cluster and the questions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feQUc8vGhNQw",
        "outputId": "32c8f1c9-254a-4b0b-fbbb-7a61c38826d2"
      },
      "source": [
        "clustered_sentences = [[] for i in range(num_clusters)]\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "\n",
        "for i, cluster in enumerate(clustered_sentences):\n",
        "    print(\"Cluster \", i+1)\n",
        "    print(cluster)\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster  1\n",
            "['Create summary tables that address therapeutics, interventions, and clinical studies?', 'Create summary tables that address diagnostics for COVID-19?', 'Create summary tables that address population studies related to COVID-19?', 'Create summary tables that address patient descriptions related to COVID-19']\n",
            "\n",
            "Cluster  2\n",
            "['What is known about transmission, incubation, and environmental stability?', 'What has been published about ethical and social science considerations?']\n",
            "\n",
            "Cluster  3\n",
            "['What do we know about vaccines and therapeutics?', 'What do we know about virus genetics, origin, and evolution?', 'What has been published about medical care?', 'What do we know about diagnostics and surveillance?']\n",
            "\n",
            "Cluster  4\n",
            "['What has been published about information sharing and inter-sectoral collaboration?']\n",
            "\n",
            "Cluster  5\n",
            "['What do we know about non-pharmaceutical interventions?']\n",
            "\n",
            "Cluster  6\n",
            "['What do we know about COVID-19 risk factors?', 'Create summary tables that address relevant factors related to COVID-19?', 'Create summary tables that address risk factors related to COVID-19?', 'Create summary tables that address material studies related to COVID-19?', 'Create summary tables that address models and open questions related to COVID-19?']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}